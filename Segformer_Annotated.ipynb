{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1. Bibliotecas - Roboflow\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "import os"
      ],
      "metadata": {
        "id": "GJoSQINOy2jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw9VNz7aJ5JR"
      },
      "outputs": [],
      "source": [
        "#2. Exporto las máscaras de segmentación\n",
        "rf = Roboflow(api_key=\"VN4WNXMOAA6kMFJVi4w0\")\n",
        "project = rf.workspace(\"prueba-segformer\").project(\"my-first-project-w4jed\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"png-mask-semantic\")\n",
        "\n",
        "#3. Verifico la ubicación de las máscaras\n",
        "print(dataset.location)\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Clase para obtener Dataset\n",
        "class SemanticSegmentationDataset(Dataset):\n",
        "    \"\"\"Image (semantic) segmentation dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, feature_extractor):\n",
        "        self.root_dir = root_dir\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.classes_csv_file = os.path.join(self.root_dir, \"_classes.csv\")\n",
        "        with open(self.classes_csv_file, 'r') as fid:\n",
        "            data = [l.split(',') for i,l in enumerate(fid) if i !=0]\n",
        "        self.id2label = {x[0]:x[1] for x in data}\n",
        "\n",
        "        image_file_names = [f for f in os.listdir(self.root_dir) if '.jpg' in f]\n",
        "        mask_file_names = [f for f in os.listdir(self.root_dir) if '.png' in f]\n",
        "\n",
        "        self.images = sorted(image_file_names)\n",
        "        self.masks = sorted(mask_file_names)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image = Image.open(os.path.join(self.root_dir, self.images[idx]))\n",
        "        segmentation_map = Image.open(os.path.join(self.root_dir, self.masks[idx]))\n",
        "\n",
        "        encoded_inputs = self.feature_extractor(image, segmentation_map, return_tensors=\"pt\")\n",
        "\n",
        "        for k,v in encoded_inputs.items():\n",
        "          encoded_inputs[k].squeeze_()\n",
        "\n",
        "        return encoded_inputs"
      ],
      "metadata": {
        "id": "oemd5UNTz9EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Extracción de los datasets para entrenamiento, validación y test\n",
        "from transformers import SegformerFeatureExtractor, SegformerImageProcessor\n",
        "\n",
        "feature_extractor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
        "feature_extractor.reduce_labels = False\n",
        "#feature_extractor.size = 128\n",
        "feature_extractor.size = 512\n",
        "\n",
        "dataset_root = \"/content/My-First-Project-1\"\n",
        "\n",
        "train_dataset = SemanticSegmentationDataset(os.path.join(dataset_root, \"train\"), feature_extractor)\n",
        "val_dataset = SemanticSegmentationDataset(os.path.join(dataset_root, \"valid\"), feature_extractor)\n",
        "test_dataset = SemanticSegmentationDataset(os.path.join(dataset_root, \"test\"), feature_extractor)\n",
        "\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=3, prefetch_factor=8)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=3, prefetch_factor=8)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=3, prefetch_factor=8)"
      ],
      "metadata": {
        "id": "QPx3DjNy0G6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de PyTorch Lightning\n",
        "!pip install pytorch-lightning\n",
        "\n",
        "# Importación de bibliotecas necesarias\n",
        "import pytorch_lightning as pl\n",
        "from transformers import SegformerForSemanticSegmentation  # Modelo SegFormer para segmentación\n",
        "from datasets import load_metric  # Para cargar métricas de evaluación\n",
        "import torch\n",
        "from torch import nn  # Módulo de redes neuronales de PyTorch\n",
        "import numpy as np\n",
        "\n",
        "# Definición de la clase principal para fine-tuning de SegFormer\n",
        "class SegformerFinetuner(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Clase que implementa el fine-tuning de SegFormer para segmentación semántica\n",
        "    usando PyTorch Lightning para manejar el ciclo de entrenamiento.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, id2label, train_dataloader=None, val_dataloader=None, test_dataloader=None, metrics_interval=100):\n",
        "        \"\"\"\n",
        "        Inicializa el fine-tuner de SegFormer.\n",
        "\n",
        "        Args:\n",
        "            id2label (dict): Diccionario de mapeo de IDs de clase a etiquetas\n",
        "            train_dataloader (DataLoader): DataLoader para datos de entrenamiento\n",
        "            val_dataloader (DataLoader): DataLoader para datos de validación\n",
        "            test_dataloader (DataLoader): DataLoader para datos de prueba\n",
        "            metrics_interval (int): Cada cuántos batches calcular métricas\n",
        "        \"\"\"\n",
        "        super(SegformerFinetuner, self).__init__()  # Inicializa la clase padre\n",
        "        self.id2label = id2label  # Diccionario para convertir IDs a nombres de clase\n",
        "        self.metrics_interval = metrics_interval  # Frecuencia para calcular métricas\n",
        "        self.train_dl = train_dataloader  # DataLoader de entrenamiento\n",
        "        self.val_dl = val_dataloader  # DataLoader de validación\n",
        "        self.test_dl = test_dataloader  # DataLoader de prueba\n",
        "        self.test_losses = []  # Lista para almacenar pérdidas durante prueba\n",
        "\n",
        "        # Calcula el número de clases y crea mapeo inverso (etiqueta -> ID)\n",
        "        self.num_classes = len(id2label.keys())\n",
        "        self.label2id = {v: k for k, v in self.id2label.items()}\n",
        "\n",
        "        # Carga el modelo pre-entrenado SegFormer con configuración personalizada\n",
        "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
        "            \"nvidia/segformer-b0-finetuned-ade-512-512\",  # Modelo base pre-entrenado\n",
        "            return_dict=False,  # Devuelve tuplas en lugar de diccionarios\n",
        "            num_labels=self.num_classes,  # Número de clases personalizado\n",
        "            id2label=self.id2label,  # Mapeo de IDs a etiquetas\n",
        "            label2id=self.label2id,  # Mapeo de etiquetas a IDs\n",
        "            ignore_mismatched_sizes=True,  # Permite ajustar tamaño de salida\n",
        "        )\n",
        "\n",
        "        self.model.train()  # Establece el modelo en modo entrenamiento\n",
        "\n",
        "        # Inicializa métricas para entrenamiento, validación y prueba\n",
        "        self.train_mean_iou = load_metric(\"mean_iou\")  # Métrica IoU para entrenamiento\n",
        "        self.val_mean_iou = load_metric(\"mean_iou\")  # Métrica IoU para validación\n",
        "        self.test_mean_iou = load_metric(\"mean_iou\")  # Métrica IoU para prueba\n",
        "\n",
        "        self.val_losses = []  # Lista para acumular pérdidas de validación\n",
        "\n",
        "    def forward(self, images, masks):\n",
        "        \"\"\"\n",
        "        Paso forward del modelo.\n",
        "\n",
        "        Args:\n",
        "            images (Tensor): Tensor de imágenes de entrada\n",
        "            masks (Tensor): Tensor de máscaras de ground-truth\n",
        "\n",
        "        Returns:\n",
        "            tuple: (loss, logits) - Pérdida y logits del modelo\n",
        "        \"\"\"\n",
        "        outputs = self.model(pixel_values=images, labels=masks)\n",
        "        return outputs  # Retorna las salidas del modelo\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        \"\"\"\n",
        "        Paso de entrenamiento para un batch de datos.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch de datos con 'pixel_values' y 'labels'\n",
        "            batch_nb (int): Número del batch actual\n",
        "\n",
        "        Returns:\n",
        "            dict: Diccionario con métricas de entrenamiento\n",
        "        \"\"\"\n",
        "        # Extrae imágenes y máscaras del batch\n",
        "        images, masks = batch['pixel_values'], batch['labels']\n",
        "\n",
        "        # Pasa los datos por el modelo\n",
        "        outputs = self(images, masks)\n",
        "        loss, logits = outputs[0], outputs[1]  # Separa pérdida y logits\n",
        "\n",
        "        # Interpola los logits al tamaño original de las máscaras\n",
        "        upsampled_logits = nn.functional.interpolate(\n",
        "            logits,\n",
        "            size=masks.shape[-2:],  # Tamaño objetivo (H, W)\n",
        "            mode=\"bilinear\",  # Método de interpolación\n",
        "            align_corners=False  # Alineación de esquinas\n",
        "        )\n",
        "        predicted = upsampled_logits.argmax(dim=1)  # Obtiene predicciones\n",
        "\n",
        "        # Agrega el batch actual a las métricas de entrenamiento\n",
        "        self.train_mean_iou.add_batch(\n",
        "            predictions=predicted.detach().cpu().numpy(),  # Predicciones\n",
        "            references=masks.detach().cpu().numpy()  # Verdades terreno\n",
        "        )\n",
        "\n",
        "        # Calcula métricas cada cierto intervalo de batches\n",
        "        if batch_nb % self.metrics_interval == 0:\n",
        "            metrics = self.train_mean_iou.compute(\n",
        "                num_labels=self.num_classes,  # Número de clases\n",
        "                ignore_index=255,  # Ignora píxeles sin etiqueta (generalmente 255)\n",
        "                reduce_labels=False,  # No reduce etiquetas\n",
        "            )\n",
        "            # Prepara métricas para logging\n",
        "            metrics = {\n",
        "                'loss': loss,\n",
        "                \"mean_iou\": metrics[\"mean_iou\"],  # IoU promedio\n",
        "                \"mean_accuracy\": metrics[\"mean_accuracy\"]  # Precisión promedio\n",
        "            }\n",
        "            # Registra métricas\n",
        "            for k, v in metrics.items():\n",
        "                self.log(k, v)\n",
        "            return metrics\n",
        "        else:\n",
        "            return {'loss': loss}  # Retorna solo la pérdida\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        \"\"\"\n",
        "        Paso de validación para un batch de datos.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch de datos de validación\n",
        "            batch_nb (int): Número del batch actual\n",
        "\n",
        "        Returns:\n",
        "            dict: Diccionario con pérdida de validación\n",
        "        \"\"\"\n",
        "        images, masks = batch['pixel_values'], batch['labels']\n",
        "        outputs = self(images, masks)\n",
        "        loss, logits = outputs[0], outputs[1]\n",
        "\n",
        "        # Interpola logits y obtiene predicciones\n",
        "        upsampled_logits = nn.functional.interpolate(\n",
        "            logits,\n",
        "            size=masks.shape[-2:],\n",
        "            mode=\"bilinear\",\n",
        "            align_corners=False\n",
        "        )\n",
        "        predicted = upsampled_logits.argmax(dim=1)\n",
        "\n",
        "        # Agrega batch a métricas de validación\n",
        "        self.val_mean_iou.add_batch(\n",
        "            predictions=predicted.detach().cpu().numpy(),\n",
        "            references=masks.detach().cpu().numpy()\n",
        "        )\n",
        "\n",
        "        # Acumula pérdida para cálculo posterior\n",
        "        self.val_losses.append(loss.detach())\n",
        "\n",
        "        return {'val_loss': loss}\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Método llamado al final de cada época de validación.\n",
        "        Calcula y registra métricas agregadas.\n",
        "        \"\"\"\n",
        "        # Calcula métricas IoU para toda la época\n",
        "        metrics = self.val_mean_iou.compute(\n",
        "            num_labels=self.num_classes,\n",
        "            ignore_index=255,\n",
        "            reduce_labels=False,\n",
        "        )\n",
        "\n",
        "        # Calcula pérdida promedio de validación\n",
        "        avg_val_loss = torch.stack(self.val_losses).mean() if self.val_losses else torch.tensor(0.0)\n",
        "        self.val_losses.clear()  # Limpia para próxima época\n",
        "\n",
        "        # Extrae métricas importantes\n",
        "        val_mean_iou = metrics[\"mean_iou\"]\n",
        "        val_mean_accuracy = metrics[\"mean_accuracy\"]\n",
        "\n",
        "        # Registra métricas (aparecen en la barra de progreso)\n",
        "        self.log(\"val_loss\", avg_val_loss, prog_bar=True, on_epoch=True)\n",
        "        self.log(\"val_mean_iou\", val_mean_iou, prog_bar=True, on_epoch=True)\n",
        "        self.log(\"val_mean_accuracy\", val_mean_accuracy, prog_bar=True, on_epoch=True)\n",
        "\n",
        "        # Prepara diccionario de métricas\n",
        "        metrics = {\n",
        "            \"val_loss\": avg_val_loss,\n",
        "            \"val_mean_iou\": val_mean_iou,\n",
        "            \"val_mean_accuracy\": val_mean_accuracy\n",
        "        }\n",
        "\n",
        "        # Registra todas las métricas\n",
        "        for k, v in metrics.items():\n",
        "            self.log(k, v, prog_bar=True, on_epoch=True)\n",
        "\n",
        "    def test_step(self, batch, batch_nb):\n",
        "        \"\"\"\n",
        "        Paso de prueba para un batch de datos.\n",
        "\n",
        "        Args:\n",
        "            batch (dict): Batch de datos de prueba\n",
        "            batch_nb (int): Número del batch actual\n",
        "\n",
        "        Returns:\n",
        "            dict: Diccionario con pérdida de prueba\n",
        "        \"\"\"\n",
        "        images, masks = batch['pixel_values'], batch['labels']\n",
        "        outputs = self(images, masks)\n",
        "        loss, logits = outputs[0], outputs[1]\n",
        "\n",
        "        # Interpola logits y obtiene predicciones\n",
        "        upsampled_logits = nn.functional.interpolate(\n",
        "            logits,\n",
        "            size=masks.shape[-2:],\n",
        "            mode=\"bilinear\",\n",
        "            align_corners=False\n",
        "        )\n",
        "        predicted = upsampled_logits.argmax(dim=1)\n",
        "\n",
        "        # Agrega batch a métricas de prueba\n",
        "        self.test_mean_iou.add_batch(\n",
        "            predictions=predicted.detach().cpu().numpy(),\n",
        "            references=masks.detach().cpu().numpy()\n",
        "        )\n",
        "\n",
        "        # Acumula pérdida para cálculo posterior\n",
        "        self.test_losses.append(loss.detach())\n",
        "\n",
        "        return {'test_loss': loss}\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Método llamado al final de la prueba.\n",
        "        Calcula y registra métricas finales de prueba.\n",
        "        \"\"\"\n",
        "        # Calcula métricas IoU para todo el conjunto de prueba\n",
        "        metrics = self.test_mean_iou.compute(\n",
        "            num_labels=self.num_classes,\n",
        "            ignore_index=255,\n",
        "            reduce_labels=False,\n",
        "        )\n",
        "\n",
        "        # Calcula pérdida promedio de prueba\n",
        "        avg_test_loss = torch.stack(self.test_losses).mean() if self.test_losses else torch.tensor(0.0)\n",
        "        self.test_losses.clear()  # Limpia para próxima ejecución\n",
        "\n",
        "        # Extrae métricas importantes\n",
        "        test_mean_iou = metrics[\"mean_iou\"]\n",
        "        test_mean_accuracy = metrics[\"mean_accuracy\"]\n",
        "\n",
        "        # Registra métricas finales (aparecen en la barra de progreso)\n",
        "        self.log(\"test_loss\", avg_test_loss, prog_bar=True)\n",
        "        self.log(\"test_mean_iou\", test_mean_iou, prog_bar=True)\n",
        "        self.log(\"test_mean_accuracy\", test_mean_accuracy, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configura el optimizador para el entrenamiento.\n",
        "\n",
        "        Returns:\n",
        "            Optimizer: Optimizador Adam con learning rate bajo\n",
        "        \"\"\"\n",
        "        return torch.optim.Adam(\n",
        "            [p for p in self.parameters() if p.requires_grad],  # Solo parámetros entrenables\n",
        "            lr=2e-05,  # Tasa de aprendizaje pequeña para fine-tuning\n",
        "            eps=1e-08  # Término épsilon para estabilidad numérica\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"Retorna el DataLoader de entrenamiento.\"\"\"\n",
        "        return self.train_dl\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"Retorna el DataLoader de validación.\"\"\"\n",
        "        return self.val_dl\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        \"\"\"Retorna el DataLoader de prueba.\"\"\"\n",
        "        return self.test_dl\n",
        "\n",
        "# Instanciación del modelo fine-tuner\n",
        "segformer_finetuner = SegformerFinetuner(\n",
        "    train_dataset.id2label,  # Mapeo de IDs a etiquetas\n",
        "    train_dataloader=train_dataloader,  # DataLoader de entrenamiento\n",
        "    val_dataloader=val_dataloader,  # DataLoader de validación\n",
        "    test_dataloader=test_dataloader,  # DataLoader de prueba\n",
        "    metrics_interval=10,  # Calcula métricas cada 10 batches\n",
        ")"
      ],
      "metadata": {
        "id": "UYbyPfs50ThW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== CONFIGURACIÓN INICIAL ====================\n",
        "# Instalación de dependencias (para Colab/Jupyter)\n",
        "!pip install pytorch-lightning transformers datasets\n",
        "\n",
        "# Importaciones esenciales\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import files  # Solo para Colab\n",
        "from IPython.display import display\n",
        "\n",
        "# Frameworks principales\n",
        "import pytorch_lightning as pl\n",
        "from transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor\n",
        "\n",
        "# ==================== DEFINICIÓN DE CALLBACKS ====================\n",
        "\"\"\"\n",
        "Callbacks son funciones que se ejecutan durante el entrenamiento para:\n",
        "1. EarlyStopping: Detener el entrenamiento si no hay mejora\n",
        "2. ModelCheckpoint: Guardar los mejores modelos\n",
        "\"\"\"\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor=\"val_mean_iou\",  # Métrica a monitorear (IoU en validación)\n",
        "    min_delta=0.00,         # Cambio mínimo para considerar mejora\n",
        "    patience=3,             # Épocas sin mejora antes de parar\n",
        "    verbose=True,           # Mostrar mensajes\n",
        "    mode=\"max\"              # Objetivo: maximizar la métrica\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    save_top_k=1,                          # Guardar solo el mejor modelo\n",
        "    monitor=\"val_mean_iou\",                # Métrica de referencia\n",
        "    mode=\"max\",                            # Maximizar el IoU\n",
        "    filename=\"best-model-{epoch:02d}-{val_mean_iou:.2f}\",  # Nombre del archivo\n",
        "    verbose=True                           # Mostrar mensajes\n",
        ")\n",
        "\n",
        "# ==================== CONFIGURACIÓN DEL ENTRENADOR ====================\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"auto\",          # Usar GPU si está disponible\n",
        "    devices=\"auto\",             # Usar todos los dispositivos\n",
        "    callbacks=[early_stop_callback, checkpoint_callback],  # Callbacks\n",
        "    max_epochs=20,              # Límite de épocas\n",
        "    val_check_interval=len(train_dataloader),  # Validar después de cada época\n",
        ")\n",
        "\n",
        "# ==================== ENTRENAMIENTO Y EVALUACIÓN ====================\n",
        "# Iniciar entrenamiento\n",
        "trainer.fit(segformer_finetuner)\n",
        "\n",
        "# Evaluar con el mejor modelo guardado\n",
        "test_results = trainer.test(ckpt_path=\"best\")\n",
        "print(\"Resultados de prueba:\", test_results)\n",
        "\n",
        "# ==================== VISUALIZACIÓN DE RESULTADOS ====================\n",
        "# Mapa de colores para las clases (personalizar según dataset)\n",
        "color_map = {\n",
        "    0: (0, 0, 0),      # Fondo - Negro\n",
        "    1: (255, 0, 0),    # Clase 1 - Rojo\n",
        "    2: (0, 255, 0),    # Clase 2 - Verde\n",
        "    3: (0, 0, 255)     # Clase 3 - Azul\n",
        "}\n",
        "\n",
        "def prediction_to_vis(prediction):\n",
        "    \"\"\"Convierte máscara de predicción a imagen RGB coloreada\"\"\"\n",
        "    vis_shape = prediction.shape + (3,)  # Añadir canales RGB\n",
        "    vis = np.zeros(vis_shape, dtype=np.uint8)\n",
        "    for class_id, color in color_map.items():\n",
        "        vis[prediction == class_id] = color\n",
        "    return Image.fromarray(vis)\n",
        "\n",
        "# Visualización comparativa (predicción vs ground truth)\n",
        "def visualize_predictions(dataloader, model, num_samples=3):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            images, masks = batch['pixel_values'], batch['labels']\n",
        "            outputs = model(images, masks)\n",
        "            logits = outputs[1] if isinstance(outputs, tuple) else outputs.logits\n",
        "\n",
        "            # Upsample logits al tamaño original\n",
        "            upsampled_logits = nn.functional.interpolate(\n",
        "                logits,\n",
        "                size=masks.shape[-2:],\n",
        "                mode=\"bilinear\",\n",
        "                align_corners=False\n",
        "            )\n",
        "            preds = upsampled_logits.argmax(dim=1).cpu().numpy()\n",
        "            masks = masks.cpu().numpy()\n",
        "\n",
        "            # Mostrar resultados\n",
        "            fig, ax = plt.subplots(num_samples, 2, figsize=(10, num_samples*5))\n",
        "            for i in range(num_samples):\n",
        "                ax[i,0].imshow(prediction_to_vis(preds[i]))\n",
        "                ax[i,0].set_title(\"Predicción\")\n",
        "                ax[i,1].imshow(prediction_to_vis(masks[i]))\n",
        "                ax[i,1].set_title(\"Ground Truth\")\n",
        "            plt.show()\n",
        "            break\n",
        "\n",
        "visualize_predictions(test_dataloader, segformer_finetuner.model)\n",
        "\n",
        "# ==================== INFERENCIA EN IMAGEN PERSONALIZADA ====================\n",
        "def predict_and_visualize(image_path, model, feature_extractor):\n",
        "    \"\"\"Proceso completo para una imagen personalizada\"\"\"\n",
        "    # 1. Cargar y preprocesar imagen\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    # 2. Predicción\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
        "\n",
        "    # 3. Postprocesamiento\n",
        "    upsampled_logits = nn.functional.interpolate(\n",
        "        logits,\n",
        "        size=image.size[::-1],  # (height, width)\n",
        "        mode=\"bilinear\",\n",
        "        align_corners=False\n",
        "    )\n",
        "    pred_mask = upsampled_logits.argmax(dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # 4. Visualización\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
        "    ax[0].imshow(image)\n",
        "    ax[0].set_title(\"Imagen Original\")\n",
        "    ax[1].imshow(prediction_to_vis(pred_mask))\n",
        "    ax[1].set_title(\"Segmentación Predicha\")\n",
        "    plt.show()\n",
        "\n",
        "    return pred_mask\n",
        "\n",
        "# ==================== INTERFAZ PARA USUARIO ====================\n",
        "def run_inference():\n",
        "    \"\"\"Función para cargar imagen y mostrar resultados\"\"\"\n",
        "    # Subir imagen (en Colab)\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        image_path = next(iter(uploaded))\n",
        "        print(f\"\\nProcesando imagen: {image_path}\")\n",
        "\n",
        "        # Realizar predicción\n",
        "        pred_mask = predict_and_visualize(\n",
        "            image_path,\n",
        "            segformer_finetuner.model,\n",
        "            feature_extractor\n",
        "        )\n",
        "\n",
        "        # Opcional: Guardar resultado\n",
        "        result_img = prediction_to_vis(pred_mask)\n",
        "        result_path = \"resultado_segmentacion.png\"\n",
        "        result_img.save(result_path)\n",
        "        print(f\"Resultado guardado como: {result_path}\")\n",
        "        return result_img\n",
        "    else:\n",
        "        print(\"No se subió ninguna imagen\")\n",
        "        return None\n",
        "\n",
        "# Ejecutar interfaz (descomentar para usar)\n",
        "# result_image = run_inference()\n",
        "# if result_image:\n",
        "#     display(result_image)\n",
        "\n",
        "# ==================== FUNCIONES ADICIONALES ====================\n",
        "def create_prediction_overlay(image_path, mask):\n",
        "    \"\"\"Crea una superposición de la imagen original con la máscara\"\"\"\n",
        "    original_img = Image.open(image_path).convert(\"RGBA\")\n",
        "    mask_img = prediction_to_vis(mask).convert(\"RGBA\")\n",
        "    mask_img = mask_img.resize(original_img.size)\n",
        "\n",
        "    # Ajustar transparencia\n",
        "    overlay = Image.blend(original_img, mask_img, alpha=0.5)\n",
        "    return overlay\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# overlay = create_prediction_overlay(\"mi_imagen.jpg\", pred_mask)\n",
        "# display(overlay)"
      ],
      "metadata": {
        "id": "6vi_ZH3R06u-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}